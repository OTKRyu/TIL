# algorithm

## SW 문제 해결

여러가지 요소를 적재적소에 배치해 큰 그림을 그릴 수 있는 능력이라고 말할 수 있지만, 추상적이기도 하고 마냥 늘리기 쉬운 것도 아니다.

이를 기르기 위해 인위적인 상황을 만들어 훈련하는 것이 효율적이다. 

### 해결 과정

1. 문제를 읽고 이해
2. 문제를 재정의
3. 계획을 세움
4. 계획을 검증
5. 실제로 구현
6. 반성 및 개선 방안 모색

### 전략

- 직관 및 체계적인 접근

## 복잡도 분석

- 알고리즘: 어떤 문제를 해결하기 위한 절차나 방법
- 알고리즘의 효율
  - 공간적 효율성: 메모리를 얼마나 쓰느냐
  - 시간적 효율성: 시간을 얼마나 줄일 수 있는가
    - 하드웨어 환경에 따라 변화
    - 소프트웨어 환경에 따라서도 변화
    - 고로 분석이 쉽지 않다.
    - 그래서 입력 크기에 대한 함수로 주로 표기하게 된다. 대표적인 표기법으로는 아래와 같은 종류들이 있다.
      - big oh
        - 점근적 상한을 의미, n이 커질 수록 최고차항이 값을 지배하게 되므로 최고차항만 쓰는 편이다.
      - big omega
        - 점근적 하한을 의미, n이 커졌을 때 최소한 이것만큼은 걸린다라고 표기하는 것이다.
      - big theta
        - big oh 와 big omega가 같은 경우 쓰는 표기법으로, n이 증가함에 따라 연산량의 증가율이 theta와 같다는 의미를 지닌다.
  - 복잡도와 완전히 반대의 개념으로 반비례한다.

- 왜 효율적인 알고리즘이 필요한가
  - 결국 주어진 시간과 공간이 한정적이기 때문
  - 이 시간과 공간을 하드웨어를 개발함으로서 늘릴 수 있지만, 하드웨어의 개발보다 훨씬 적은 자원으로도 알고리즘을 개선함으로서 효율을 높일 수 있음

## python 표준 입출력

- 입력
  - input : 표준 입력, 받은 것을 문자열로 취급
  - eval(input()) : 받은 입력값을 명령어로 인식, 실제로 실행이 되어버리기 때문에 위험하다.
- 출력
  - print : 표준 출력, 개행 문자 포함
  - print('%d' %number) : formatting 한 출력
- 파일 내용
  - sys.stdin = open("a.txt","r")
    - 파이참의 경우 표준입력이 1mb라서 이걸 넘어가면 제대로 인지를 못한다. 이럴 경우 그냥 파일 자체를 열어서 가져와야하는데 이럴 경우 쓰게 된다. 
  - sys.stdout = open("output.txt", "w")


## 정수
### 비트연산


- MSB, LSB : most significant bit, lest significant bit 로 비트 중에 가장 큰 값을 담당하고 있는 자리와 가장 작은 값을 담당하고 있는 자리를 말한다.

- `&`: 비트 단위의 and연산
- `|` : 비트 단위의 or연산
- `^` : 비트 단위의 xor연산, 비트를 반전시킬 떄도 쓸 수 있다.
- `~` : 모든 비트를 반전, 다만 int의 경우 이렇게 하면 보수법 떄문에 내가 원하는 수가 나오지 않을 수 있으니 이점 유의
- `<<` : 비트열을 왼쪽으로 이동, 즉 2배 
- `>>` : 비트열을 오른쪽으로 이동, 즉 1/2배
- 비트를 통해 음수를 표현하는 방법
  - 부호 크기 표현 : 맨 앞자리 수를 부호를 나타내는 방법. 간단하지만, 연산에서 제대로 된 값을 뽑아내려면 추가 연산이 필요하기 때문에 쓰기 어렵다.
  - 1의 보수 표현 : 비트로 나타낸 수를 0과 1을 반전시킨 값을 음수로 표현
  - 2의 보수 표현 : 1의 보수로 만든 후 1을 더하는 것으로 음수를 표현한 것
    - 양수 음수 구분 확실
    - 음수를 더하는 단순한 방식으로 셈 수행 가능
    - 음수끼리의 비교연산에서 생기는 모순 해결
    - 0의 표현 방식 하나로 고정 가능
- 엔디안(endianness)
  - 컴퓨터의 메모리와 같은 1차원의 공간에 여러 개의 연속된 대상을 배열하는 방법을 의미하며 hw architecture마다 다르다.
  - 속도 향상을 위해 바이트 단위와 워드 단위를 변환하여 연산 할 때 올바로 이해하지 않으면 오류를 발생 시킬 수 있다.
  - 이 엔디안 때문에 16진수를 2진수로 바꾸거나 할 때 저장순서가 다르기 때문에 출력순서가 달라지거나하는 경우가 생길 수 있다.
  - 빅 엔디안
    - 보통 큰 단위가 앞에 나옴, 네트워크가 대표적이다.
  - 리틀 엔디안
    - 작은 단위가 앞에 나옴, 대다수 데스크탑 컴퓨터가 이 방법을 따르고 있다.
- 진수 변환
  - 2~4~8~16 끼리의 변환과 10진수로의 변환도 있다마는 기본적으로 원리는 별거 없다.

### 실수

컴퓨터는 실수를 근사적으로 표현하기 때문에 항상 정확한 결과를 기대해서는 안 되고 근삿값 정도를 기대해야 한다.

고로 유효 자릿수를 알아 둬야 한다.

32 비트 실수형의 경우 유효자릿수는 6자리이고, 64비트 실수형의 경우 유효자릿수는 15자리정도이다.

- 실수의 변환

  - 각 자리에 해당하는 실수들을 더해서 만든다.

- 실수의 표현

  - 부동소수점 표기법을 사용
  - 소수점의 위치를 고정시키고 밑수의 지수승으로 표현
  - 가수부분으로 값이 어떤지를 저장해놓기 때문에 숫자의 크기가 지수단위로 차이가 나게 되면, 같은 길이의 가수부를 가지고 있다고 한들 소수부분의 자릿수가 같기를 기대할 수 없다.
  - 파이썬에서는 더 많은 비트를 이용해서 넓은 범위의 실수를 표현할 수 있다. 최대 1.8 * 10 ^308, 이 이상은 inf로 표현. 이 때 inf는 실수표현이므로 정수와 관련된 문제에서는 사용하지 않아야 한다. 최소는 10 ^ -324 정도이다. 이 이하는 사실상 0과 다름이 없다고 표시한다.

- 실수의 저장

  - 단정도 실수
    - 부호 1비트, 지수 8비트, 가수 23비트
    - 실제로 만들 때는 가장 큰 자리의 숫자가 1의 자리에 오도록 지수부를 조정하고, 나머지 가수 부분은 23비트로 만든다.
    - 이 때 지수부에 쓸 수 있는 것은 8비트이지만 음수와 양수 모두 써야하는데 이 때 2의 보수가 아닌 익세스표현법이라는 것을 쓴다.
    - 익세스 표현법은 가장 큰 값을 절반크기까지 만약 8비트라면 128에 할당하고 가장 작은 값을 -127에 할당하는 방법으로, 간단하게 생각하면 음수 중 가장 작은 값을 0으로 할당하고 그로부터 다른 수들을 할당하는 방법이다.
  - 배정도 실수 : 주로 이걸 쓴다.
    - 부호 1비트, 지수 11비트, 가수 52비트

## basic algorithm

- 표현하는 방법
  - 수도코드(pseudocode)
    - 말 그대로 유사코드
    - 어떤 언어에 맞는 코드는 아니지만 생각한 것이 어떻게 동작할 것인지에 대해 간략하게 코드형식으로 적은 것이다.
  - 순서도
  
- 좋은 알고리즘
  - 정확성
  - 작업량
    - 시간복잡도 : 실제 걸리는 시간 혹은 실행되는 명령문의 개수를 계산
      - 빅 오 표기법 : 가장 큰 영향력을 주는 n에 대한 항만을 계수를 생략하여 표시
  - 메모리 사용량
  - 단순성
  - 최적성
  
- 배울 때 주의할 점
  - 대부분의 문제가 제한사항이 많지 않은 경우 여러가지 풀이법이 존재한다.
  - 많은 풀이법을 알 수록 좋다.

파이썬으로 구현할 시 주의점

- 파이썬을 쓸 경우 음수의 나누기 연산이 내가 원하는 연산 결과대로 나오는지를 확인해봐야한다.


### 반복(iteration)과 재귀(recursion)
비슷한 작업 가능
다만 둘 다 같은 시간 복잡도가 걸릴 시 함수 호출에 대한 시간이 걸리기 때문에 재귀가 시간이 좀 더 걸림

재귀는 더 작은 구조로 반복이 진행될 시 요긴하게 사용 가능

- 반복구조
  - 초기화
  - 조건검사(check control expression)
  - 반복할 명령문 실행(action)
  - 업데이트(loop update)
- 재귀 함수
  - 함수 내부에서 직접 혹은 간접으로 자기 자신을 호출하는 함수
  - 기본 부분과 유도 부분으로 구성된다
  - 재귀적 프로그램을 작성하는 것은 반복 구조에 비해 간결하고 이해가 쉽다.
  - 함수 호출은 메모리 스택을 쓰기 때문에 반복횟수가 증가하면 할수록 메모리 및 속도에서 성능저하가 발생한다.
- 해결할 문제에 따라 2가지 방법 중 나은 것을 선택
- 재귀는 설계가 간단하고 자연스러운 경우 선택
- 다만 재귀 알고리즘은 반복 보다 더 많은 메모리와 연산을 필요로하므로, 입력 값이 커질수록 재귀 알고리즘보다는 반복이 효율적이다.


### 완전검색

문제의 해법으로 생각할 수 있는 모든 경우릐 수를 나열해보고 확인하는 기법

brute-force or generate and test 기법이라고 불린다.

일반적으로 경우의 수가 적은 경우에만 효율적이다.

죄다 하기 때문에 방식이 정확하다면 답은 어지간하면 찾을 수 있다. 그러므로 시작은 완전검색으로 시작하는 편이 좋다. 다만 느리기 때문에 방식을 찾아낸 후 이에 효율적으로 적용할 수 있는 알고리즘을 추가로 찾아 적용하는 것이 바람직하다.

많은 종류의 문제들이 특정 조건을 만족하는 경우 또는 요소를 찾는 것이다.

전형적으로 순열, 조합, 부분집합과 같은 조합론적 문제들과 연관된다.

#### 순열

- 서로 다른 것들 중 몇개를 뽑아 한 줄로 나열
- nPr로 표기, nPr = n!/(n-r)!, nPn = n!
- 순서화된 요소들의 집합에서 최선의 방법을 찾는 것과 관련이 있다.
- 생성 방법에는 여러가지 방법이 있는데 대표적으로 사전적 순서대로 생성하는 방법, 최소 변경 방법, next permutation등등이 있다.
- 생성이 가면갈수록 많은 연산을 요구하기 때문에 조건에 맞는 순열만을 추출하기 위해 재귀로 짜는 편이다.

```python
# 단순 반복을 통한 방법
for i in range(3):
    for j in range(3):
        if i!=j:
            for k in range(3):
                if i!=k and j!=k:
                    print([i,j,k])
# 재귀 방식으로 구현한 최소 교환 방식의 순열 생성
array = range(n)
def swap(k, i):
    array[k],array[i] = array[i], array[k]
def perm(n,k):
    if k == n:
        print(array)
    else:
        for i in range(k,n):
            swap(k,i)
            perm(n,k+1)
            swap(k,i)
```

#### 부분 집합

- 집합에 포함된 원소들을 선택
- 다수의 중요 알고리즘들이 원소들의 그룹에서 최적의 부분 집합을 찾는 것이다.
- n(power set) = 2^n 
- for문을 여러번 중첩하여 사용하는 방법

```python
# 단순 반복을 통해 얻는 방법
for i in range(2):
    bit[0] = i
    for j in range(2):
        bit[1] = j
        for k in range(2):
            bit[2] = k
            for l in range(3):
                if bit[l] == 1:
                    print(array[l])
```

- 비트연산자를 사용하여 만드는 방법
  - 결국 부분 집합을 구할때 원소가 들어가냐 아니냐로 정하기 때문에 이를 0과 1로 치환하면 2진수로 이를 표현할 수 있다.

  - 그래서 이 부분에 비트 연산자와 관련된 내용을 넣어놓는다.

    - `&` : 비트 단위 and(i&(1<<j): i를 비트로 바꾼 것과 j번째에만 1이 있는 비트와의 비트단위의 and연산을 진행, i의 j번째 비트가 1인지 아닌지를 1과 0으로 리턴)
- `|` : 비트 단위 or
- `<<` : 비트 열을 왼쪽으로 이동( 1<<n: 1을 n만큼 비트단위 왼쪽으로 이동, 나타내는 값은 결국 2^n)
- `>>` : 비트 열은 오른쪽으로 이동

```python
for i in range(1<<len(arr)):
    for j in range(len(arr)):
        if i & (1<<j):
            #부분집합마다 할 내용
```

#### 부분합

- 반복문 두개로 모든 요소를 훑어가면서 계산을 해도 괜찮음
- 하지만 부분합 자체만을 구할 거라면 인덱스를 중복해서 돌리는 곳이 많음
- 이를 줄이기 위해 쓰는 기법 중 슬라이딩 기법이 있다.
  - 그래서 처음에만 부분합을 계산하고 그 뒤부터는 부분합의 첫번째 요소를 빼고 마지막 요소를 더해 다음 부분합을 구함
  - 이렇게 하면 연산량을 줄일 수 있음

#### 조합

- 서로 다른 n개의 원소 중 r개를 순서 없이 골라낸 것
- 조합의 수식 nCr = nPr/r! or nCr = n-1Cr-1 + n-1Cr

```python
n = 5
r = 3
arr = list(range(1,6))
sel = [0]*r
def combination(idx,sidx):
    if sidx == r:
        print(sel)
        return
    if idx == n:
        return
    sel(sidx) = arr[idx]
    # 실제로 뽑은 경우
    combination(idx+1,sidx+1)
    # 안 뽑고 다음으로 넘긴 경우
    combination(idx+1,sidx)
    
def combination(idx, sidx):
    if sidx == r:
        print(sel)
        return
    
    for i in range(idx,n):
        sel[sidx] = arr[i]
        combination(idx+1,sidx+1)
def f(i,j,n,r): # 원래 집합의 수 n, 뽑을 수의 갯수 r, 시작지점 j, 현재 몇 개 뽑았는지 i
    if i==r:
        print(c)
    else:
        for k in range(j, n-r+i+1):
            c[i] = A[k]
            f(i+1, k+1, n, r)
# 그냥 반복으로
M = 8
for j in range(i+1, M-2+1):
    for j in range(i+1,M-2+1):
        for k in range(j+1,M-1+1):
            print(i,j,k)
```



### 탐욕 알고리즘(greedy algorithm)

최적해를 구하는데 사용되는 근시안적 방법, 이런 접근을 시도하는 문제를 최적화 문제라고 부르기도 한다.

여러 갈래 길 중 그 순간에 최적이라고 생각하는 것을 선택해 진행

지역적으로는 최선을 거듭했지만, 그렇다고 최종결과가 최적이라는 보장은 없다.

일반적으로 생각나는대로 접근하면 greedy 접근이라고 한다.

1. 현재 상태의 부분 문제의 최적 해를 구함, 이를 부분해 집합에 추가
2. 부분해 집합이 실행가능한지, 조건에 맞는 지 검사
3. 부분해 집합이 해가 되는지 검사

이러한 접근의 특징들은 아래와 같다.

- 제한된 조건안에서 근시안적인 해를 찾는 것이기 때문에 구현이 간단한 편이다.
- 한번 선택한 것을 번복하지 않고 앞으로 쭉 나아간다.
- 이러한 방법으로 풀리려면 근시안적인 해가 최적해로 가는것을 증명해야하며, 모집합을 줄여나가서 결국에는 최적해에 다다를 수 있는지에 대해서도 증명해야한다.
- top down 방식

대표적인 탐욕 기법의 알고리즘

- prim
- kruskal
- dijkstra
- huffman tree & code

대표적인 문제로 아래와 같은 문제들이 있다.

- knapsack
  - 0-1 knapsack
    - 물건을 넣고 뺄 수만 있는 문제
    - 완전 탐색의 경우
      - 모든 집합의 부분집합을 만들고 조건에 해당하는 부분집합 중 가장 가치가 큰 집합을 선택
      - 기본적으로 2^n만큼의 연산이 걸리기 때문에 n이 조금만 커져도 힘들어진다.
    - 탐욕적 방법
      - 무게가 작은 순, 가치가 높은 순, 키로당 가치가 높은 순으로 해도 최적해가 나타나지 않을 수도 있다.
  - fractional knapsack
    - 이 경우 물건을 자를 수 있기 때문에 키로당 가치가 가장 높은 것들 순서대로 넣으면 된다.
- 회의실 배정하기
  - 회의는 시작 시간과 종료 시간이 있으며, 회의 시간이 겹치는 회의는 동시에 열릴 수 있다.
  - 가능한 많은 회의가 열리기 위해서는 어떤 선택을 해야하는가.
  - 양립할 수 있는 회의들을 모은 부분집합 중 가장 큰 집합을 구하는 문제
  - 탐욕적 방법
    1. 종료시간 순으로 정렬한 한다.
    2. 종료 시간이 가장 빠른 회의를 선택
    3. 이 후 종료시간 이후에 시작하는 회의들만을 모집합으로 보고 이 과정을 반복
- baby-gin
  - 숫자들의 갯수를 배열에 저장
  - triplet 혹은 run을 조사, 없다면 끝
  - 있다면 남은 것이 run 혹은 triplet인지 검사

### dp(dynamic programming)

동적 계획 알고리즘은 그리디 알고리즘과 같이 최적화 문제를 해결하는 알고리즘이다

입력 크기가 작은 부분 문제를 해결하여 그 해를 이용해 큰 크기의 부분 문제들을 해결해 최종적인 문제를 해결하는 알고리즘이다.

memoizaion의 경우 재귀적 구조에 쓰기 보다는 dp로 구현한 것이 성능면에서 효율적(저장하는 것은 같으나 재귀는 함수호출횟수를 계속 갉아먹기 때문)

bottom-up 방식

### 백트래킹(backtracking)

해를 찾는 도중에 막히면 되돌아가서 해를 찾아 가는 기법

최적화와 결정 문제에 사용 가능

결정 문제:해가 존재하는지의 여부를 yes or no로 대답하는 문제

```python
#psudo code
def backtracking(v):
	if promissing(v):
		if there is a solution at v:
			write the solution
		else:
			for u in each child of v:
				checknode(u)		
```



#### 백트래킹과 dfs와의 차이

- 백트래킹의 경우 성공 가능성이 낮은 경로는 조기에 차단해 진행하지 않음(prunning 가지치기), 하지만 dfs는 완전 탐색이다.
- dfs는 문제에 따라 다르지만 최악의 경우 현실적으로 불가능할 수 있다.
- 백트래킹 또한 최악의 경우 지수함수 시간만큼이 걸리며 이 또한 현실적으로 불가능하다. 

#### 백트래킹의 실제 기법

- 모든 후보를 검사하지 않는다.
- 어떤 노드의 유망성을 점검한 후 유망하지 않다고 결정되면 그 노드의 부모로 돌아간 후 다른 자식 노드로 이동
- 유망하다는 것은 해답으로 이어질 가능성을 가지고 판단하며, 가능성 있으면 유망하다, 없으면 유망하지 않다고 한다.
- 이런 유망하지 않은 노드를 조기에 쳐내는 것은 가지치기라고 한다.

#### 백트래킹의 절차

1. 상태 공간 트리의 깊이 우선 검색 실시
2. 노드가 유망한지 점검
3. 유망하지 않다면 그 노드의 부모 노드로 돌아가 검색을 계속

### 분할 정복 알고리즘

문제를 분할한 후 분할한 작은 문제를 정복하여 해결된 해답들을 통합하여 큰 문제에 대답하는 방법

#### 설계 전략

- 분할:  해결할 문제를 여러 개의 작은 부분으로 나눈다.
- 정복 : 작은 부분의 문제를 해결한다.
- 통합 : 필요하다면 작은 부분의 해답들을 모아 큰 문제의 해답으로 합친다.


